# -*- coding: utf-8 -*-
"""pruning_all_2022_06_24.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1hgBe-YxxSncGIFCvIYYgqeK4svg2_Dnw
"""

import numpy as np
import pandas as pd
import torch.nn.functional as F
import torch
#from PIL import Image
from torchvision import models
import random
#import sklearn
from os import listdir
import cv2
#from collections import Counter
from torch import nn
import time

from torch.utils.data import Dataset
#from torchvision import transforms
#import os
#from torchstat import stat
#import copy
#import math
#import torchvision
#from random import sample

#global variable
dict_L1_norm = {}
mean_L1_norm = {}
std_L1_norm = {}
dict_L2_norm = {}
mean_L2_norm = {}
std_L2_norm = {}
APoZ_dict = {}
mean_APoZ = {}
std_APoZ = {}
apoz_eleCount = {}

model_choose = 3  #1 => resnet50 , 2 => resnet101 , 3 => resnet152
criteria_choose = 2  #1 => L1 , 2 => L2 , 3 => APoZ
regularization_choose = 2 #1 => lasso , 2 => ridge , 3 => group_lasso
path = 'training_record/StanfordCarsr_resnet101_1epoch_pruned_0926_le5_maxacc1.txt'  # write txt
weight_save_path = '/home/xxx/model/StanfordCars/pruned/StanfordCarsr_resnet101_1epoch_pruned_weight_0926_le5_maxacc1.pt'
model_save_path = '/home/xxx/model/StanfordCars/pruned/StanfordCarsr_resnet101_1epoch_pruned_0926_le5_maxacc1.pt'

model_out_classnum = 196

load_all_seed = int(6)
load_from_gen_seed = int(8)


device = torch.device("cuda")

dict_name_modules = {}
dict_name_parameters = {}

f = open(path, 'w')


def dict_parameters(model):
  global dict_name_parameters
  for name,parameters in model.named_parameters():
    dict_name_parameters[name] = parameters


def dict_modules(model):
  global dict_name_modules
  for name,module in model.named_modules():
    if 'conv' in name:
      dict_name_modules[name] = module

"""# load model"""

def load_model():
  global model_choose
  if model_choose == 1:
    model = models.resnet50(pretrained=False)  #change
    fc_feature = model.fc.in_features    #change
    model.fc = torch.nn.Linear(fc_feature,model_out_classnum)  #change
    model.load_state_dict(torch.load('/home/xxx/model/StanfordCars/StanfordCarsr_resnet50_3epoch_le5.pt')) # ResNet50 nofinetune

  elif model_choose == 2:
    model = models.resnet101(pretrained=False)
    fc_feature = model.fc.in_features    #change
    model.fc = torch.nn.Linear(fc_feature,model_out_classnum)  #change
    model.load_state_dict(torch.load('/home/xxx/StanfordCars/StanfordCarsr_resnet101_3epoch_le5.pt'))
    
  else:
    model = models.resnet152(pretrained=False)
    fc_feature = model.fc.in_features    #change
    model.fc = torch.nn.Linear(fc_feature,model_out_classnum)  #change
    model.load_state_dict(torch.load('/home/xxx/model/StanfordCars/StanfordCarsr_resnet152_3epoch_le5.pt'))
    

  return model

"""# pruning criteria"""

def criteria_select(mode, model, validation_dataset = None):
  global dict_L1_norm, dict_L2_norm, APoZ_dict, mean_L1_norm, mean_L2_norm, mean_APoZ, std_L1_norm, std_L2_norm, std_APoZ
  if mode == 1:
    dict_L1_norm  = L1_norm_criteria(model)
    mean_L1_norm = mean(mean_L1_norm, dict_L1_norm)
    std_L1_norm = std(std_L1_norm, mean_L1_norm, dict_L1_norm)
    return dict_L1_norm, mean_L1_norm, std_L1_norm
  elif mode == 2:
    dict_L2_norm  = L2_norm_criteria(model)
    mean_L2_norm = mean(mean_L2_norm, dict_L2_norm)
    std_L2_norm = std(std_L2_norm, mean_L2_norm, dict_L2_norm)

    return dict_L2_norm, mean_L2_norm, std_L2_norm
  elif mode == 3:
    APoZ_dict  = APoZ(model)
    mean_APoZ = mean(mean_APoZ, APoZ_dict)
    std_APoZ = std(std_APoZ, mean_APoZ, APoZ_dict)

    return APoZ_dict, mean_APoZ, std_APoZ


  return None, None, None

"""L1_norm"""

def L1_norm_criteria(model):
  global dict_L1_norm
  for name,parameters in model.named_parameters():
    if "conv" in name:
      temp = abs(parameters).sum(dim = 3).sum(dim = 2).sum(dim=1)
      dict_L1_norm[name[:-7]] = torch.div((temp*1000).type(torch.int64),torch.numel(parameters[0])).type(torch.int64)

  return dict_L1_norm

"""L2_norm"""

def L2_norm_criteria(model):
  global dict_L2_norm
  for name,parameters in model.named_parameters():
    if "conv" in name:
      temp = parameters.pow(2.0).sum(dim = 3).sum(dim = 2).sum(dim=1)
      dict_L2_norm[name[:-7]] = torch.div((temp*1000000).type(torch.int64),torch.numel(parameters[0])).type(torch.int64)
  return dict_L2_norm

"""APoZ"""
def _get_module(model, submodule_key):
  tokens = submodule_key.split('.')
  sub_tokens = tokens[:-1]
  cur_mod = model
  for s in sub_tokens:
      cur_mod = getattr(cur_mod, s)
  return getattr(cur_mod, tokens[-1])

def filter_0_percent(temp):
  global device
  temp = temp.squeeze()
  temp = temp.permute(1,0,2,3)
  apoz = torch.zeros(temp.shape[0],dtype = torch.float32).to(device = torch.device('cuda'))
  for i in range(temp.shape[0]):
    temp[i] = F.relu(temp[i])
    compare = torch.zeros((temp.shape[1], temp.shape[2],temp.shape[3]),dtype = torch.float32).to(device = torch.device('cuda'))
    apoz[i] += torch.eq(temp[i],compare).sum(dim=2).sum(dim = 1).sum(dim = 0).item()

  return apoz / (temp.shape[1]*temp.shape[2]*temp.shape[3])

def APoZ(model, input):
  features = []
  def hook(module, input, output):
    features.append(output.clone().detach())
    del output

  global dict_name_modules, APoZ_dict
  APoZ_dict = {}

  handle = []
  for name, modules in dict_name_modules.items():
    handle.append(modules.register_forward_hook(hook))

  model = model.to(device=torch.device('cuda')) # add
  input = input.to(device=torch.device('cuda'))
  y = model(input)

  for i in range(len(handle)):
    handle[i].remove()

  temp = list(dict_name_modules)

  for i in range(len(features)):
    APoZ_dict[temp[i]] = filter_0_percent(features[i])
  
  del features
  del handle

  torch.cuda.empty_cache()

"""mean"""

def mean(mean_dict, criteria_dict):
  for name in criteria_dict.keys():
    a = criteria_dict[name]
    temp = torch.div(torch.bincount(a),torch.sum(torch.bincount(a)))
    for i in range(temp.shape[0]):
      temp[i] = temp[i]*i

    mean_dict[name] = int(torch.sum(temp).item())
  return mean_dict

"""std"""

def std(std_dict, mean_dict, criteria_dict):
  for name in criteria_dict.keys():

    for i in range(len(criteria_dict[name])):
      if (i != 0):
        std_dict[name] += (criteria_dict[name][i] - mean_dict[name]) * (criteria_dict[name][i] - mean_dict[name])
      else:
        std_dict[name] = (criteria_dict[name][i] - mean_dict[name]) * (criteria_dict[name][i] - mean_dict[name])
    std_dict[name] = int(pow(std_dict[name]/len(criteria_dict[name]), 0.5).item())
  return std_dict

"""# pruning

pruning module
"""

def _set_module(model, submodule_key, module):
  tokens = submodule_key.split('.')
  sub_tokens = tokens[:-1]
  cur_mod = model
  for s in sub_tokens:
      cur_mod = getattr(cur_mod, s)
  setattr(cur_mod, tokens[-1], module)

"""make mask"""

#True->will remove  -7 => remove.weight
def filter_mask(mode, layerName):
  global dict_L1_norm, mean_L1_norm, std_L1_norm, dict_L2_norm, mean_L2_norm, std_L2_norm, APoZ_dict, mean_APoZ, std_APoZ, device

  if mode == 1:  #L1-norm
    mask = torch.le(dict_L1_norm[layerName[:-7]], mean_L1_norm[layerName[:-7]] - std_L1_norm[layerName[:-7]])
  elif mode == 2: #L2-norm
    mask = torch.le(dict_L2_norm[layerName[:-7]], mean_L2_norm[layerName[:-7]] - std_L2_norm[layerName[:-7]])
 
  else:       #APoZ
    mask = torch.ge(APoZ_dict[layerName[:-7]], mean_APoZ[layerName[:-7]] - std_APoZ[layerName[:-7]])

  return mask

def fill_value_in_new_layer(model, mask, layerName, dim):   
  global device
  temp = model.state_dict()[layerName] #####

  if "conv" in layerName and "weight" in layerName:

    if dim == 1:
      temp = torch.permute(temp, (1,0,2,3))

    for i in range(temp.shape[0]):
      if mask[i]:
        temp[i] = 0.0

    j = 0      
    for i in range(temp.shape[0]):
      total = torch.eq(temp[j], 0.0).sum(dim=2).sum(dim=1).sum(dim=0)
      
      if total.item() == temp.shape[1]*temp.shape[2]*temp.shape[3]:
        temp = temp[torch.arange(temp.size(0)) != j]
        j -= 1

      j += 1

    if dim == 1:
      temp = torch.permute(temp, (1,0,2,3))

  else:
    j = 0
    for i in range(temp.shape[0]):
      if mask[i]:
        temp = temp[torch.arange(temp.size(0)) != j]
        j -= 1

      j += 1

  return temp

def make_new_layer(model, mode, layerName, layerName_bias, next_layerName, layer_bn_name, layer_bn_name_bias):
  global device, dict_name_modules

  mask = filter_mask(mode, layerName)

  #print(mask)
  dle_filter_ele_count = mask.sum(dim=0)
  if dle_filter_ele_count< 20:
    return None

  layer_module = dict_name_modules[layerName[:-7]]
  next_layer_module = dict_name_modules[next_layerName[:-7]]

  buffer = []

  buffer.append(fill_value_in_new_layer(model, mask, layerName, 0))
  buffer.append(fill_value_in_new_layer(model, mask, next_layerName, 1))
  buffer.append(fill_value_in_new_layer(model, mask, layer_bn_name, 0))
  buffer.append(fill_value_in_new_layer(model, mask, layer_bn_name_bias, 0))


  #conv
  if layer_module.kernel_size == (3,3):
    _set_module(model, layerName[:-7], nn.Conv2d(in_channels = layer_module.in_channels, out_channels = (layer_module.out_channels - dle_filter_ele_count), kernel_size = layer_module.kernel_size, stride = layer_module.stride, padding = layer_module.padding, bias=False))
  elif layer_module.kernel_size == (1,1):
    _set_module(model, layerName[:-7], nn.Conv2d(in_channels = layer_module.in_channels, out_channels = (layer_module.out_channels - dle_filter_ele_count), kernel_size = layer_module.kernel_size, stride = layer_module.stride, bias=False))

  #next_conv
  if next_layer_module.kernel_size == (3,3):
    _set_module(model, next_layerName[:-7], nn.Conv2d(in_channels = (next_layer_module.in_channels - dle_filter_ele_count), out_channels = next_layer_module.out_channels, kernel_size = next_layer_module.kernel_size, stride = next_layer_module.stride, padding = next_layer_module.padding, bias=False))
  elif next_layer_module.kernel_size == (1,1):
    _set_module(model, next_layerName[:-7], nn.Conv2d(in_channels = (next_layer_module.in_channels - dle_filter_ele_count), out_channels = next_layer_module.out_channels, kernel_size = next_layer_module.kernel_size, stride = next_layer_module.stride, bias=False))

  #bn
  _set_module(model, layer_bn_name[:-7], nn.BatchNorm2d(num_features = (layer_module.out_channels - dle_filter_ele_count), eps=1e-05, momentum=0.1, affine=True, track_running_stats=True))


  #------------------
  model.state_dict()[layerName].copy_(buffer[0])

  model.state_dict()[next_layerName].copy_(buffer[1])
  
  model.state_dict()[layer_bn_name].copy_(buffer[2])

  model.state_dict()[layer_bn_name_bias].copy_(buffer[3])

  return model

"""
# model training function"""

def del_tensor_ele(arr,index1,index2, train_len):
  arr1 = arr[0:index1]
  arr2 = arr[index2:train_len]
  return torch.cat((arr1,arr2),dim = 0)

def loss_regularization(r_loss, model, mode):
  regularization_loss = 0
  if mode == 0:   #no regularization
    return r_loss
  elif mode == 1:  #LASSO
    for param in model.parameters():
      regularization_loss += torch.sum(abs(param))

    return r_loss + 0.0001 * regularization_loss
  elif mode == 2:  #Ridge
    for param in model.parameters():
      regularization_loss += torch.sqrt(torch.sum(param.pow(2.0)))

    return r_loss + 0.0001 * regularization_loss
  else:        #Group LASSO
    regularization_lasso = 0
    for param in model.parameters():
      regularization_lasso += torch.sum(abs(param))
    
    regularization_group_filter = 0
    regularization_group_channel = 0
    for name,parameters in model.named_parameters():
      if "conv" in name:
        a = parameters.pow(2.0).sum(dim = 3).sum(dim = 2)
        regularization_group_filter += pow(3,0.5) * a.sum(dim =1).pow(0.5).sum(dim=0)
        regularization_group_channel += pow(2,0.5) * a.pow(0.5).sum(dim =1).sum(dim=0)

    return r_loss + 0.001 * regularization_lasso + 0.0001 * regularization_group_filter + 0.001 * regularization_group_channel

def validate(model, train_dataset, val_dataset, loss_fn):
  train_loader = torch.utils.data.DataLoader(train_dataset , batch_size = 16,shuffle = False,num_workers=1, pin_memory=True, drop_last=True)
  val_loader = torch.utils.data.DataLoader(val_dataset , batch_size = 16,shuffle = False,num_workers=1, pin_memory=True, drop_last=True)

  correct = 0
  total = 0
  with torch.no_grad():
    for imgs, labels in train_loader:
        imgs = imgs.to(device = device)
        labels = labels.to(device = device)
        outputs = model(imgs)
        predicted = torch.max(outputs,dim = 1)
        total += labels.shape[0]
        correct += int((predicted.indices == labels).sum())

  val_correct = 0
  val_total = 0
  val_loss_train = 0.0
  with torch.no_grad():
    for imgs, labels in val_loader:
        imgs = imgs.to(device = device)
        labels = labels.to(device = device)
        val_outputs = model(imgs)
        val_loss = loss_fn(val_outputs,labels)
        val_loss_train += val_loss.item()
        val_predicted = torch.max(val_outputs,dim = 1)
        val_total += labels.shape[0]
        val_correct += int((val_predicted.indices == labels).sum())
  
  return correct/total, val_correct/val_total, val_loss_train/len(val_loader)

def training_loop(n_epochs,optimizer,model,loss_fn,train_dataset,validation_dataset, mode):
  
  for epoch in range(0,n_epochs):
    train_loader = torch.utils.data.DataLoader(train_dataset[epoch%10],batch_size = 16,shuffle= True,num_workers=1, pin_memory=True, drop_last=True)
    loss_train = 0.0
    count = 1
    model.train()  #change
    for imgs,labels in train_loader:
      imgs = imgs.to(device = device) # ori
      labels = labels.to(device = device) # ori
      outputs = model(imgs)
      r_loss = loss_fn(outputs,labels)
      
      loss = loss_regularization(r_loss, model, mode)

      optimizer.zero_grad()
      loss.backward()
      optimizer.step()
      loss_train += r_loss.item()
      
    
    model.eval()  #change
    correct, val_correct, val_loss = validate(model, train_dataset[epoch%10], validation_dataset[epoch%10], loss_fn)

    #loss1.append(loss_train/len(train_loader))
    print('Epoch {}, Training loss {}, Training accuracy {}'.format(epoch + 1,loss_train/len(train_loader), correct))
    print('    , Validation loss {}, Validation accuracy {}\n'.format(val_loss,val_correct))
    
    f.write('Epoch '+str(epoch + 1)+' Training loss '+str(loss_train/len(train_loader))+' Training accuracy '+str(correct)+'\n')
    f.write('    , Validation loss '+str(val_loss)+', Validation accuracy '+str(val_correct)+'\n\n')

"""# inference for testing"""

# test
def test(copy_model, test_dataset):
  total_loss = 0.0
  total_accuracy = 0.0

  error_label_counetr = [0]*8
  TN=0
  FN=0
  TP=0
  FP=0

  copy_model.eval()

  test_total = 0
  test_loss_train = 0.
  test_correct = 0
  test_loader = torch.utils.data.DataLoader(test_dataset , batch_size = 1,shuffle = False,num_workers=1, pin_memory=True, drop_last=True)
  loss_fn = torch.nn.CrossEntropyLoss()
  test_start_time = time.time()

  with torch.no_grad():
    for imgs, labels in test_loader:
      imgs = imgs.to(device = device)
      labels = labels.to(device = device)
      test_outputs = copy_model(imgs)  #CHANGE
      test_loss = loss_fn(test_outputs,labels)
      test_loss_train += test_loss.item()
      test_predicted = torch.max(test_outputs,dim = 1)
      test_total += labels.shape[0]
      test_correct += int((test_predicted.indices == labels).sum())
      
    total_accuracy += test_correct/test_total

  test_end_time = time.time()
  
  return total_accuracy, (test_end_time -  test_start_time) # add

"""# load data"""

#proccess dataset

class my_Dataset(Dataset):
    def __init__(self, images, labels):
        self.images = images
        self.labels = labels

    def __len__(self):
        return self.images.shape[0]

    def __getitem__(self, idx):
        return self.images[idx], self.labels[idx]

# load whole B dataset

def load_all_img_B(class_num, train_img_num, test_img_num):
    path = "../xxx/finetune/LiteonRacingData/B/"+ str(class_num) + "/" 
    img_train = []
    img_test = []
    f_name = []
    count = 0
    for f in listdir(path):
      if f == "desktop.ini":
        continue
      else:
        f_name.append(f)
    f_name.sort()
    random.seed(load_all_seed)
    random.shuffle(f_name)    
    
    for name in f_name:
      if(class_num!=0):
        if count < test_img_num:
          img_test.append(cv2.resize(cv2.cvtColor(cv2.imread(path + name),cv2.IMREAD_COLOR), (224, 224), interpolation=cv2.INTER_CUBIC))
          count += 1
        elif count < 10:
          img_train.append(cv2.resize(cv2.cvtColor(cv2.imread(path + name),cv2.IMREAD_COLOR), (224, 224), interpolation=cv2.INTER_CUBIC))
          count += 1
        else:
          break
      else:
        if count < test_img_num:
          img_test.append(cv2.resize(cv2.cvtColor(cv2.imread(path + name),cv2.IMREAD_COLOR), (224, 224), interpolation=cv2.INTER_CUBIC))
          count += 1
        elif count < train_img_num + test_img_num:
          img_train.append(cv2.resize(cv2.cvtColor(cv2.imread(path + name),cv2.IMREAD_COLOR), (224, 224), interpolation=cv2.INTER_CUBIC))
          count += 1
        else:
          break
    return img_train, img_test



def load_img_from_Liteon_Charlie_gen_B(class1, remaining_count):
  img_x_train = []
  path = "/home/xxx/Liteon_Charlie_gen/B/"+ str(class1) + "_gen/"
  count = 0
  f_name = []
  
  for f in listdir(path):
    f_name.append(f)
  f_name.sort()
  random.seed(load_from_gen_seed)
  random.shuffle(f_name)
  
  # fill up 30 frames
  for name in f_name:
    if count < remaining_count:
      img_x_train.append(cv2.resize(cv2.cvtColor(cv2.imread(path + name),cv2.IMREAD_COLOR), (224, 224), interpolation=cv2.INTER_CUBIC))
      count += 1
    else:
      break
  return img_x_train


if __name__ == '__main__': 
  device = torch.device('cuda')
  

  #-------------------dataset proccessing begin---------------------# 
  all_transforms = transforms.Compose([
  transforms.Resize([224,224]),
  transforms.ToTensor(),
  transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))])
    
  stanfordCars_train = torchvision.datasets.StanfordCars(root = '/home/xxx/StanfordCars/stanfordCars_train', split = 'train', transform=all_transforms, download=True)
  
  stanfordCars_test = torchvision.datasets.StanfordCars(root = '/home/xxx/StanfordCars/stanfordCars_test', split = 'test', transform=all_transforms, download=True)
  
  
  print(stanfordCars_train.__len__())
  
  img_class_train = [[] for _ in range(model_out_classnum)]
  
  img_class_test = [[] for _ in range(model_out_classnum)]
  
  count = 0
  
  for i in range(stanfordCars_train.__len__()):
    img_class_train[stanfordCars_train[i][1]].append(stanfordCars_train[i][0])  
  
  for i in range(stanfordCars_test.__len__()):
    img_class_test[stanfordCars_test[i][1]].append(stanfordCars_test[i][0])   
    count += 1
    
  random.seed(4)
  
  train_imgs = []
  train_labels = []
  test_imgs = []
  test_labels = []
  
  
  n = 100
  count = 0
  for i in range(model_out_classnum):
    imgs_train = sample(img_class_train[i], 24)   
    imgs_test = sample(img_class_test[i],10)
    test_imgs = test_imgs + imgs_test
    train_imgs = train_imgs + imgs_train
    train_labels = train_labels + [i]*24  
    test_labels = test_labels + [i]*10
    count += 1
    
  print(train_imgs[0].dtype)  
  
  for i in range(len(train_imgs)):
    train_imgs[i] = train_imgs[i].numpy()
    
  for i in range(len(test_imgs)):
    test_imgs[i] = test_imgs[i].numpy()
    
  index = [i for i in range(len(train_imgs))] 
  random.shuffle(index)
  index = np.array(index)
  train_imgs = np.array(train_imgs)[index]
  train_labels = np.array(train_labels)[index]
  test_imgs = np.array(test_imgs)
  test_labels = np.array(test_labels)
  
  
  train_imgs = torch.from_numpy(train_imgs)
  train_labels = torch.from_numpy(train_labels)
  test_imgs = torch.from_numpy(test_imgs)
  test_labels = torch.from_numpy(test_labels)
  
    
  
  x_cross_train = []
  x_cross_val = []
  y_cross_train = []
  y_cross_val = []
  
  
  len_one_tenth_x_train = int(len(train_imgs)/10)
  print("len_one_tenth_x_train:"+str(len_one_tenth_x_train))
  
  for i in range(10):    #10-fold corss validation
    x_buffer_train = train_imgs
    y_buffer_train = train_labels
    x_cross_val.append(x_buffer_train[0+len_one_tenth_x_train*i:len_one_tenth_x_train+len_one_tenth_x_train*i])
    y_cross_val.append(y_buffer_train[0+len_one_tenth_x_train*i:len_one_tenth_x_train+len_one_tenth_x_train*i])
    x_cross_train.append(del_tensor_ele(x_buffer_train,0+len_one_tenth_x_train*i,len_one_tenth_x_train+len_one_tenth_x_train*i, len_one_tenth_x_train*10))
    y_cross_train.append(del_tensor_ele(y_buffer_train,0+len_one_tenth_x_train*i,len_one_tenth_x_train+len_one_tenth_x_train*i, len_one_tenth_x_train*10))
  
  
  train_dataset = []
  val_dataset = []
  for i in range(10):
    train_dataset.append(my_Dataset(x_cross_train[i],y_cross_train[i]))
    val_dataset.append(my_Dataset(x_cross_val[i],y_cross_val[i]))
    
    
  test_dataset = my_Dataset(test_imgs ,test_labels)

  #-------------------dataset proccessing end---------------------# 

  # load_model
  model = load_model().to(device = device)

  loss_fn = torch.nn.CrossEntropyLoss()
  n_epochs = 1
  optimizer = torch.optim.Adam(model.parameters(),lr = 1e-5)

  accuracy = []
  recall = []
  precision = []
  tp_list = []
  tp_fp_list = []
  time_list = []
  layer = []

  dict_parameters(model) 
  dict_modules(model)
  validate_set =[]
  dict_criteria, mean_criteria, std_criteria = criteria_select(criteria_choose, model, validate_set)


  start_time = time.time()
  ##compute which layer will start pruned
  strart_find_key = None
  strart_next_key = None
  temp = list(mean_criteria)
  if criteria_choose == 1 or criteria_choose == 2:
    min = 1000.0
    for keys in mean_criteria:
      if not "conv3" in keys:
        if mean_criteria[keys] < min:
          strart_find_key = keys
          strart_next_key = temp[temp.index(keys) + 1]
          min = mean_criteria[keys]
  else:
    max = 0.0
    for keys in mean_criteria:
      if not "conv3" in keys:
        if mean_criteria[keys] > max:
          strart_find_key = keys
          strart_next_key = temp[temp.index(keys) + 1]
          max = mean_criteria[keys]

  print('----------------')
  print('mean:',mean_criteria)
  print('----------------')
  print('which layer will start pruned:',strart_find_key)
  print('----------------')
  
  f.write('\n----------------\n mean : ')
  f.writelines(str(mean_criteria))
  f.write('\n----------------\n which layer will start pruned : ')
  f.writelines(str(strart_find_key))
  f.write('\n----------------\n')
 

  find_key = strart_find_key
  next_key = strart_next_key
  
  
  a, time1 = test(model, test_dataset)
  max_acc  = a

  #first down
  count = 0
  while True: 
    while True:
      if dict_name_modules[find_key].out_channels > 32:
        x = find_key.split('.')
        copy_model = make_new_layer(model, criteria_choose, find_key + ".weight", find_key + '.bias', next_key + '.weight', x[0] + '.' + x[1] + ".bn" + x[2][4] + '.weight', x[0] + '.' + x[1] + ".bn" + x[2][4] + '.bias')
        
        
        if copy_model == None:
          dict_parameters(model) 
          dict_modules(model)
          dict_criteria, mean_criteria, std_criteria = criteria_select(criteria_choose, model, validate_set)
          break
          

        copy_model = copy_model.to(device = device)
        
        if count % 1 == 0:
          training_loop(n_epochs,optimizer,copy_model,loss_fn,train_dataset,val_dataset, regularization_choose)
          a, time1 = test(copy_model, test_dataset)
          
          print('accuracy', a)
          
          
          if a < (max_acc - 0.00):
            print('max_acc-2.0 :',  max_acc - 0.00)
            dict_parameters(model) 
            dict_modules(model)
            dict_criteria, mean_criteria, std_criteria = criteria_select(criteria_choose, model, validate_set)
            break
            
            
          if a >= max_acc:
            max_acc = a
            torch.save(copy_model, model_save_path[:-3] + 'best.pt')
              
            
          layer.append(find_key)
          print(layer)
          print(_get_module(copy_model, find_key))
          accuracy.append(a)
          time_list.append(time1)

          model = copy_model
          count += 1
          
        else:
          model = copy_model
          count += 1
          

      else:
        dict_parameters(model) 
        dict_modules(model)
        dict_criteria, mean_criteria, std_criteria = criteria_select(criteria_choose, model, validate_set)
        break

      dict_parameters(model) 
      dict_modules(model)
      dict_criteria, mean_criteria, std_criteria = criteria_select(criteria_choose, model, validate_set)

    if len(temp) - temp.index(find_key) == 2:
      dict_parameters(model) 
      dict_modules(model)
      dict_criteria, mean_criteria, std_criteria = criteria_select(criteria_choose, model, validate_set)
      break

    if "conv3" in temp[temp.index(find_key) + 1]:
      find_key = temp[temp.index(find_key) + 2]
      next_key = temp[temp.index(next_key) + 2]
    else:
      find_key = temp[temp.index(find_key) + 1]
      next_key = temp[temp.index(next_key) + 1]

  find_key = strart_find_key
  next_key = strart_next_key
    
  #and then up
  while True: 
    while True:
      if dict_name_modules[find_key].out_channels > 32:
        copy_model = make_new_layer(model, criteria_choose, find_key + ".weight", find_key + '.bias', next_key + '.weight', find_key[:8] + ".bn" + find_key[13] + '.weight', find_key[:8] + ".bn" + find_key[13] + '.bias')
        if copy_model == None:
          dict_parameters(model) 
          dict_modules(model)
          dict_criteria, mean_criteria, std_criteria = criteria_select(criteria_choose, model, validate_set)
          break

        copy_model = copy_model.to(device = device)
        
        if count % 1 == 0:
          training_loop(n_epochs,optimizer,copy_model,loss_fn,train_dataset,val_dataset, regularization_choose)
          a, time1 = test(copy_model, test_dataset)
          print('accuracy', a)
          if a < (max_acc - 0.00):
            print('max_acc-2.0 :',  max_acc - 0.00)
            dict_parameters(model) 
            dict_modules(model)
            dict_criteria, mean_criteria, std_criteria = criteria_select(criteria_choose, model, validate_set)
            break
  
            
          if a >= max_acc:
            max_acc = a
            torch.save(copy_model, model_save_path[:-3] + 'best.pt')
            
    
          layer.append(find_key)
          print(layer)
          print(_get_module(copy_model, find_key))
          accuracy.append(a)
  
          time_list.append(time1)

          model = copy_model
          count += 1
        else:
          model = copy_model
          count += 1

      else:
        
        dict_parameters(model) 
        dict_modules(model)
        dict_criteria, mean_criteria, std_criteria = criteria_select(criteria_choose, model, validate_set)
        break

      dict_parameters(model) 
      dict_modules(model)
      dict_criteria, mean_criteria, std_criteria = criteria_select(criteria_choose, model, validate_set)


    if temp.index(find_key) == 1:
      dict_parameters(model) 
      dict_modules(model)
      dict_criteria, mean_criteria, std_criteria = criteria_select(criteria_choose, model, validate_set)
      break

    if "conv3" in temp[temp.index(find_key) - 1]:
      find_key = temp[temp.index(find_key) - 2]
      next_key = temp[temp.index(next_key) - 2]
    else:
      find_key = temp[temp.index(find_key) - 1]
      next_key = temp[temp.index(next_key) - 1]

  end_time = time.time()

  print('the counts of pruning: ',count)
  print('----------------')
  print('the time of pruning : ', end_time-start_time)
  print('----------------')
  
  f.write('the counts of pruning : '+str(count)+'\n')
  f.write('----------------\n')
  f.write('the time of pruning : '+str(end_time-start_time)+'\n')
  f.write('----------------\n')
  

  model1 = model.to(device=torch.device('cpu'))

  stat(model1,(3,224,224))
  print('----------------')
  f.write('----------------\n')

  ori_resnet = load_model()

  print('ori_resnet:')
  stat(ori_resnet,(3,224,224))
  print('----------------')
  f.write('----------------\n')

  print('accuracy : ',accuracy)
  print('----------------')
  f.write('accuracy : ')
  f.writelines(str(accuracy))
  f.write('\n----------------\n')

  f.write('time : ')
  f.writelines(str(time_list))
  f.write('\n----------------\n')
  f.write('layer : ')
  f.writelines(str(layer))
  f.close()

  #model = copy_model
  # save weight
  torch.save(model.state_dict(), weight_save_path)
  # save whole model
  torch.save(model, model_save_path)
  
