{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "28Ky5RU_wCeL",
        "outputId": "44f881cd-9880-46ac-9835-697c1fa17421"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RPAElkM6weUM"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import random\n",
        "import pandas as pd\n",
        "import torch\n",
        "from torchvision import transforms\n",
        "from PIL import Image\n",
        "from torchvision import models\n",
        "from sklearn.utils import shuffle\n",
        "import sklearn\n",
        "from os import listdir\n",
        "import cv2\n",
        "import time\n",
        "import copy\n",
        "from skimage import exposure\n",
        "from skimage.exposure import match_histograms\n",
        "from google.colab.patches import cv2_imshow\n",
        "from torch.autograd import Variable\n",
        "from random import sample\n",
        "from torch import nn\n",
        "from torch import autograd\n",
        "import torch.nn.functional as F"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lMLHC1GQweWx"
      },
      "outputs": [],
      "source": [
        "# 讀入所有原始資料\n",
        "def load_all_img(AorB, class_num, p_train_num, p_test_num):\n",
        "  path = \"/content/drive/MyDrive/LiteonRacingData/\" + str(AorB) + \"/\" + str(class_num) + \"/\" \n",
        "  img_train = []\n",
        "  img_test = []\n",
        "  f_name = []\n",
        "  #ori_imgName = []\n",
        "  for f in listdir(path):\n",
        "    if f == \"desktop.ini\":\n",
        "      continue\n",
        "    else:\n",
        "      f_name.append(f)\n",
        "  f_name.sort()\n",
        "  random.seed(load_all_seed)\n",
        "  random.shuffle(f_name)\n",
        "  \n",
        "  count = 0\n",
        "  for name in f_name:\n",
        "    if count < p_test_num:\n",
        "      img_test.append(cv2.resize(cv2.imread(path + name), (224,224), cv2.INTER_CUBIC))\n",
        "      count += 1\n",
        "    elif count < p_train_num + p_test_num:\n",
        "      img_train.append(cv2.resize(cv2.imread(path + name), (224,224), cv2.INTER_CUBIC))\n",
        "      count += 1\n",
        "    else:\n",
        "      break\n",
        "  return img_train, img_test\n",
        "\n",
        "#讀入增量資料\n",
        "def open_image_from_Liteon_Charlie_gen(AorB, classNum, folder_ForG, sheet_num=0, load_all=False):\n",
        "  img_x_train = []\n",
        "  f_name = []\n",
        "  path = \"\"\n",
        "  if AorB != \"AtransB\":\n",
        "    path = \"/content/drive/MyDrive/Liteon_Charlie_gen/\"+str(AorB)+\"/\"+ str(classNum) + \"_\" + str(folder_ForG) + \"/\"\n",
        "  else:\n",
        "    path = \"/content/drive/MyDrive/Liteon_Charlie_gen/AtransB/\"+str(classNum)+\"/\"\n",
        "\n",
        "  for f in listdir(path):\n",
        "    f_name.append(f)\n",
        "  f_name.sort()\n",
        "  random.seed(load_from_gen_seed)\n",
        "  random.shuffle(f_name)\n",
        "  \n",
        "  if load_all == True:\n",
        "    for name in f_name:\n",
        "      img_x_train.append(cv2.resize(cv2.imread(path + name), (224,224), cv2.INTER_CUBIC))\n",
        "  else:\n",
        "    if sheet_num <= len(f_name):\n",
        "      for i in range(sheet_num):\n",
        "        img_x_train.append(cv2.resize(cv2.imread(path + f_name[i]), (224,224), cv2.INTER_CUBIC))\n",
        "    else:\n",
        "      print(\"要求超過數量! sheet_num需小於\", str(len(f_name)))\n",
        "      return None\n",
        "  return img_x_train\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ThBwmrmEweZT"
      },
      "outputs": [],
      "source": [
        "device = torch.device('cuda')\n",
        "  \n",
        "A_p_train_num = int(420) \n",
        "A_p_test_num = int(25)\n",
        "  \n",
        "B_p_train_num = int(85) \n",
        "B_p_test_num = int(5)\n",
        "\n",
        "load_all_seed = int(6)\n",
        "load_from_gen_seed = int(8)\n",
        "\n",
        "from torch.utils.data import Dataset\n",
        "class my_Dataset(Dataset):\n",
        "    def __init__(self, images, labels):\n",
        "        self.images = images\n",
        "        self.labels = labels\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.images.shape[0]\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.images[idx], self.labels[idx]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AVvLa3ZSwecD",
        "outputId": "46880f09-320f-4cc7-d48f-399c38c55a96"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "len(img_x_train): 3360\n",
            "len(img_y_train): 3360\n",
            "len(img_x_test): 200\n",
            "len(img_y_test): 200\n"
          ]
        }
      ],
      "source": [
        "# 載入 A 資料集\n",
        "\n",
        "img10_x_train, img10_x_test = load_all_img('A', 0, A_p_train_num, A_p_test_num)\n",
        "img11_x_train, img11_x_test = load_all_img('A', 1, A_p_train_num, A_p_test_num)\n",
        "img13_x_train, img13_x_test = load_all_img('A', 3, A_p_train_num, A_p_test_num)\n",
        "img14_x_train, img14_x_test = load_all_img('A', 4, A_p_train_num, A_p_test_num)\n",
        "  \n",
        "img12_x_train, img12_x_test = load_all_img('A', 2, A_p_train_num, A_p_test_num)\n",
        "img15_x_train, img15_x_test = load_all_img('A', 5, A_p_train_num, A_p_test_num)\n",
        "img16_x_train, img16_x_test = load_all_img('A', 6, A_p_train_num, A_p_test_num)\n",
        "img17_x_train, img17_x_test = load_all_img('A', 7, A_p_train_num, A_p_test_num)\n",
        "\n",
        "# A 的2 5 6 7 使用翻轉圖片補資料\n",
        "\n",
        "img12_x_train += open_image_from_Liteon_Charlie_gen('A', 2, \"flip\", 0, True)\n",
        "img15_x_train += open_image_from_Liteon_Charlie_gen('A', 5, \"flip\", 0, True)\n",
        "img16_x_train += open_image_from_Liteon_Charlie_gen('A', 6, \"flip\", 0, True)\n",
        "img17_x_train += open_image_from_Liteon_Charlie_gen('A', 7, \"flip\", A_p_train_num-len(img17_x_train))\n",
        "\n",
        "# A 的 2 5 6 使用gen圖片補齊資料\n",
        "\n",
        "img12_x_train += open_image_from_Liteon_Charlie_gen('A', 2, \"gen\", A_p_train_num-len(img12_x_train))\n",
        "img15_x_train += open_image_from_Liteon_Charlie_gen('A', 5, \"gen\", A_p_train_num-len(img15_x_train))\n",
        "img16_x_train += open_image_from_Liteon_Charlie_gen('A', 6, \"gen\", A_p_train_num-len(img16_x_train))\n",
        "\n",
        "p_train_num = A_p_train_num\n",
        "p_test_num = A_p_test_num\n",
        "\n",
        "img10_y_train = [0]*p_train_num\n",
        "img10_y_test = [0]*p_test_num\n",
        "\n",
        "img11_y_train = [1]*p_train_num\n",
        "img11_y_test = [1]*p_test_num\n",
        "\n",
        "img12_y_train = [2]*p_train_num\n",
        "img12_y_test = [2]*p_test_num\n",
        "\n",
        "img13_y_train = [3]*p_train_num\n",
        "img13_y_test = [3]*p_test_num\n",
        "\n",
        "img14_y_train = [4]*p_train_num\n",
        "img14_y_test = [4]*p_test_num\n",
        "\n",
        "img15_y_train = [5]*p_train_num\n",
        "img15_y_test = [5]*p_test_num\n",
        "\n",
        "img16_y_train = [6]*p_train_num\n",
        "img16_y_test = [6]*p_test_num\n",
        "\n",
        "img17_y_train = [7]*p_train_num\n",
        "img17_y_test = [7]*p_test_num\n",
        "\n",
        "#串接所有類別的訓練資料 (x,y)\n",
        "img_x_train = img10_x_train + img11_x_train + img12_x_train + img13_x_train + img14_x_train + img15_x_train + img16_x_train + img17_x_train\n",
        "img_y_train = img10_y_train + img11_y_train + img12_y_train + img13_y_train + img14_y_train + img15_y_train + img16_y_train + img17_y_train\n",
        "  \n",
        "print('len(img_x_train):',len(img_x_train))\n",
        "print('len(img_y_train):',len(img_y_train))\n",
        "\n",
        "\n",
        "#串接所有類別的測試資料 (x,y)\n",
        "img_x_test = img10_x_test + img11_x_test + img12_x_test + img13_x_test + img14_x_test + img15_x_test + img16_x_test + img17_x_test\n",
        "img_y_test = img10_y_test + img11_y_test + img12_y_test + img13_y_test + img14_y_test + img15_y_test + img16_y_test + img17_y_test\n",
        "print('len(img_x_test):',len(img_x_test))\n",
        "print('len(img_y_test):',len(img_y_test))\n",
        "\n",
        "\n",
        "img_x_train = np.array(img_x_train)\n",
        "img_x_test = np.array(img_x_test)\n",
        "\n",
        "img_x_train = img_x_train.astype(\"float32\")\n",
        "for i in range(len(img_x_train)):\n",
        "  img_x_train[i] = img_x_train[i]/255.0\n",
        "\n",
        "img_x_test = img_x_test.astype(\"float32\")\n",
        "for i in range(len(img_x_test)):\n",
        "  img_x_test[i] = img_x_test[i]/255.0\n",
        "\n",
        "x_train_A = torch.zeros(len(img_x_train),3,224,224,dtype = torch.float32)\n",
        "for i in range(len(img_x_train)): \n",
        "  x_train_A[i] = torch.from_numpy(img_x_train[i]).permute(2,1,0)#for BGR、HSV(cv2預設)\n",
        "\n",
        "x_test_A = torch.zeros(len(img_x_test),3,224,224,dtype = torch.float32)\n",
        "for i in range(len(img_x_test)): \n",
        "  x_test_A[i] = torch.from_numpy(img_x_test[i]).permute(2,1,0)#for BGR、HSV(cv2預設)\n",
        "\n",
        "y_train_A = torch.from_numpy(np.array(img_y_train))\n",
        "y_test_A = torch.from_numpy(np.array(img_y_test))\n",
        "\n",
        "test_dataset_A = my_Dataset(x_test_A, y_test_A)\n",
        "\n",
        "# 回傳x_validation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hzqQAJayweeu",
        "outputId": "fda958c4-ca72-47d3-f33e-51e5afeb47bf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "len(img_x_train): 680\n",
            "len(img_y_train): 680\n",
            "len(img_x_test_B): 40\n",
            "len(img_y_test_B): 40\n"
          ]
        }
      ],
      "source": [
        "# 讀入B所有資料\n",
        "img10_x_train_B, img10_x_test_B = load_all_img('B', 0, B_p_train_num, B_p_test_num)\n",
        "img11_x_train_B, img11_x_test_B = load_all_img('B', 1, B_p_train_num, B_p_test_num)\n",
        "img12_x_train_B, img12_x_test_B = load_all_img('B', 2, B_p_train_num, B_p_test_num)\n",
        "img13_x_train_B, img13_x_test_B = load_all_img('B', 3, B_p_train_num, B_p_test_num)\n",
        "img14_x_train_B, img14_x_test_B = load_all_img('B', 4, B_p_train_num, B_p_test_num)\n",
        "img15_x_train_B, img15_x_test_B = load_all_img('B', 5, B_p_train_num, B_p_test_num)\n",
        "img16_x_train_B, img16_x_test_B = load_all_img('B', 6, B_p_train_num, B_p_test_num)\n",
        "img17_x_train_B, img17_x_test_B = load_all_img('B', 7, B_p_train_num, B_p_test_num)\n",
        "\n",
        "\n",
        "# B 的 1~7類從翻轉圖片補\n",
        "img11_x_train_B += open_image_from_Liteon_Charlie_gen('B', 1, \"filp\", 0, True) # 只要所需訓練集大小不低於20張，此處皆不用改(flip一類有15張)\n",
        "img12_x_train_B += open_image_from_Liteon_Charlie_gen('B', 2, \"filp\", 0, True)\n",
        "img13_x_train_B += open_image_from_Liteon_Charlie_gen('B', 3, \"filp\", 0, True)\n",
        "img14_x_train_B += open_image_from_Liteon_Charlie_gen('B', 4, \"filp\", 0, True)\n",
        "img15_x_train_B += open_image_from_Liteon_Charlie_gen('B', 5, \"filp\", 0, True)\n",
        "img16_x_train_B += open_image_from_Liteon_Charlie_gen('B', 6, \"filp\", 0, True)\n",
        "img17_x_train_B += open_image_from_Liteon_Charlie_gen('B', 7, \"filp\", 0, True)\n",
        "\n",
        "# B 的 1~7 使用gen圖片補齊資料\n",
        "\n",
        "img11_x_train_B += open_image_from_Liteon_Charlie_gen('B', 1, \"gen\", B_p_train_num-len(img11_x_train_B))\n",
        "img12_x_train_B += open_image_from_Liteon_Charlie_gen('B', 2, \"gen\", B_p_train_num-len(img12_x_train_B))\n",
        "img13_x_train_B += open_image_from_Liteon_Charlie_gen('B', 3, \"gen\", B_p_train_num-len(img13_x_train_B))\n",
        "img14_x_train_B += open_image_from_Liteon_Charlie_gen('B', 4, \"gen\", B_p_train_num-len(img14_x_train_B))\n",
        "img15_x_train_B += open_image_from_Liteon_Charlie_gen('B', 5, \"gen\", B_p_train_num-len(img15_x_train_B))\n",
        "img16_x_train_B += open_image_from_Liteon_Charlie_gen('B', 6, \"gen\", B_p_train_num-len(img16_x_train_B))\n",
        "img17_x_train_B += open_image_from_Liteon_Charlie_gen('B', 7, \"gen\", B_p_train_num-len(img17_x_train_B))\n",
        "\n",
        "p_train_num = B_p_train_num\n",
        "p_test_num = B_p_test_num\n",
        "\n",
        "img10_y_train_B = [0]*p_train_num\n",
        "img10_y_test_B = [0]*p_test_num\n",
        "\n",
        "img11_y_train_B = [1]*p_train_num\n",
        "img11_y_test_B = [1]*p_test_num\n",
        "\n",
        "img12_y_train_B = [2]*p_train_num\n",
        "img12_y_test_B = [2]*p_test_num\n",
        "\n",
        "img13_y_train_B = [3]*p_train_num\n",
        "img13_y_test_B = [3]*p_test_num\n",
        "\n",
        "img14_y_train_B = [4]*p_train_num\n",
        "img14_y_test_B = [4]*p_test_num\n",
        "\n",
        "img15_y_train_B = [5]*p_train_num\n",
        "img15_y_test_B = [5]*p_test_num\n",
        "\n",
        "img16_y_train_B = [6]*p_train_num\n",
        "img16_y_test_B = [6]*p_test_num\n",
        "\n",
        "img17_y_train_B = [7]*p_train_num\n",
        "img17_y_test_B = [7]*p_test_num\n",
        "\n",
        "#串接所有類別的訓練資料 (x,y)\n",
        "img_x_train_B = img10_x_train_B + img11_x_train_B + img12_x_train_B + img13_x_train_B + img14_x_train_B + img15_x_train_B + img16_x_train_B + img17_x_train_B\n",
        "img_y_train_B = img10_y_train_B + img11_y_train_B + img12_y_train_B + img13_y_train_B + img14_y_train_B + img15_y_train_B + img16_y_train_B + img17_y_train_B\n",
        "\n",
        "print('len(img_x_train):',len(img_x_train_B))\n",
        "print('len(img_y_train):',len(img_y_train_B))\n",
        "\n",
        "\n",
        "# 打混訓練資料\n",
        "index = [i for i in range(len(img_x_train_B))] \n",
        "random.shuffle(index)\n",
        "index = np.array(index)\n",
        "img_x_train_B = np.array(img_x_train_B)[index]\n",
        "img_y_train_B = np.array(img_y_train_B)[index]\n",
        "\n",
        "# 串接所有類別的測試資料 (x,y)\n",
        "img_x_test_B = img10_x_test_B + img11_x_test_B + img12_x_test_B + img13_x_test_B + img14_x_test_B + img15_x_test_B + img16_x_test_B + img17_x_test_B\n",
        "img_y_test_B = img10_y_test_B + img11_y_test_B + img12_y_test_B + img13_y_test_B + img14_y_test_B + img15_y_test_B + img16_y_test_B + img17_y_test_B\n",
        "print('len(img_x_test_B):',len(img_x_test_B))\n",
        "print('len(img_y_test_B):',len(img_y_test_B))\n",
        "\n",
        "img_x_train_B = img_x_train_B.astype(\"float32\")\n",
        "for i in range(len(img_x_train_B)):\n",
        "  img_x_train_B[i] = img_x_train_B[i]/255.0\n",
        "\n",
        "\n",
        "for i in range(len(img_x_test_B)):\n",
        "  img_x_test_B[i] = img_x_test_B[i]/255.0\n",
        "\n",
        "def del_tensor_ele(arr,index1,index2, train_len):\n",
        "  arr1 = arr[0:index1]\n",
        "  arr2 = arr[index2:train_len]\n",
        "  return torch.cat((arr1,arr2),dim = 0)\n",
        "\n",
        "x_train_B = torch.zeros(len(img_x_train_B),3,224,224,dtype = torch.float32)\n",
        "x_test_B = torch.zeros(len(img_x_test_B),3,224,224,dtype = torch.float32)\n",
        "for i in range(len(img_x_train_B)): \n",
        "  x_train_B[i] = torch.from_numpy((img_x_train_B[i])).permute(2,1,0)#for BGR、HSV(cv2預設)\n",
        "for i in range(len(img_x_test_B)): \n",
        "  x_test_B[i] = torch.from_numpy((img_x_test_B[i])).permute(2,1,0)#for BGR、HSV(cv2預設)\n",
        "\n",
        "\n",
        "y_train_B = torch.from_numpy(np.array(img_y_train_B))\n",
        "y_test_B = torch.from_numpy(np.array(img_y_test_B))\n",
        "\n",
        "#交叉驗證處理\n",
        "x_cross_train_B = []\n",
        "x_cross_val_B = []\n",
        "y_cross_train_B = []\n",
        "y_cross_val_B = []\n",
        "\n",
        "#10折交叉驗證\n",
        "len_one_tenth_x_train = int(len(x_train_B)/10)\n",
        "\n",
        "for i in range(10):\n",
        "  x_buffer_train = x_train_B\n",
        "  y_buffer_train = y_train_B\n",
        "  x_cross_val_B.append(x_buffer_train[0+len_one_tenth_x_train*i:len_one_tenth_x_train+len_one_tenth_x_train*i])\n",
        "  y_cross_val_B.append(y_buffer_train[0+len_one_tenth_x_train*i:len_one_tenth_x_train+len_one_tenth_x_train*i])\n",
        "  x_cross_train_B.append(del_tensor_ele(x_buffer_train,0+len_one_tenth_x_train*i,len_one_tenth_x_train+len_one_tenth_x_train*i, len_one_tenth_x_train*10))\n",
        "  y_cross_train_B.append(del_tensor_ele(y_buffer_train,0+len_one_tenth_x_train*i,len_one_tenth_x_train+len_one_tenth_x_train*i, len_one_tenth_x_train*10))\n",
        "\n",
        "\n",
        "train_dataset_B = []\n",
        "val_dataset_B = []\n",
        "for i in range(10):\n",
        "  train_dataset_B.append(my_Dataset(x_cross_train_B[i],y_cross_train_B[i]))\n",
        "  val_dataset_B.append(my_Dataset(x_cross_val_B[i],y_cross_val_B[i]))\n",
        "\n",
        "test_dataset_B = my_Dataset(x_test_B, y_test_B)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8u7SkTrjweh2"
      },
      "outputs": [],
      "source": [
        "dict_name_modules_A = {}\n",
        "dict_name_modules_B = {}\n",
        "load_all_seed = int(6)\n",
        "load_from_gen_seed = int(8)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vTWkqGz2wekG"
      },
      "outputs": [],
      "source": [
        "#change\n",
        "feature_A = []\n",
        "feature_B = []\n",
        "feature_tmp = []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bja_3-bUwenV"
      },
      "outputs": [],
      "source": [
        "def dict_modules(model, AorB):\n",
        "  count = 0\n",
        "  global dict_name_modules_A, dict_name_modules_B\n",
        "  for name,module in model.named_modules():\n",
        "    #if 'conv' in name:\n",
        "    #  dict_name_modules[name] = module\n",
        "    #  count += 1\n",
        "    if 'layer1.0.conv1' == name or 'layer2.0.conv1' == name or \"layer3.0.conv1\" == name:\n",
        "      if AorB == 'A':\n",
        "        dict_name_modules_A[name] = module\n",
        "      elif AorB == 'B':\n",
        "        dict_name_modules_B[name] = module\n",
        "      count += 1\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PNrvUFBAwetD"
      },
      "outputs": [],
      "source": [
        "#萃取feature_map\n",
        "def feature_map(model, input, choose_layer, module_name, single, AorB):\n",
        "  features = []\n",
        "\n",
        "  def hook(module, input, output):\n",
        "    features.append(input[0].clone().detach())\n",
        "    del output\n",
        "\n",
        "  global dict_name_modules_A, dict_name_modules_B, feature_tmp, feature_A, feature_B\n",
        "  \n",
        "\n",
        "  handle = []\n",
        "  if AorB == 'A':\n",
        "    handle.append(dict_name_modules_A[module_name].register_forward_hook(hook))\n",
        "  elif AorB == 'B':\n",
        "    handle.append(dict_name_modules_B[module_name].register_forward_hook(hook))\n",
        "\n",
        "  model = model.to(device=torch.device('cuda')) # add\n",
        "  input = input.to(device=torch.device('cuda'))\n",
        "  y = model(input)\n",
        "\n",
        "  for i in range(len(handle)):\n",
        "    handle[i].remove()\n",
        "\n",
        "  feature_tmp = features[0].cpu().detach()\n",
        "  del features\n",
        "  del handle\n",
        "\n",
        "  torch.cuda.empty_cache()\n",
        "\n",
        "\n",
        "  return feature_tmp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i6GQfH4WwM_v"
      },
      "outputs": [],
      "source": [
        "random.seed(time.time())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QnmltzfuwtM6"
      },
      "outputs": [],
      "source": [
        "#change\n",
        "def list_clear():\n",
        "  global feature_tmp\n",
        "  feature_tmp.clear()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q2HrSyX8wtTA"
      },
      "outputs": [],
      "source": [
        "#選擇哪一層之後需要凍結\n",
        "def freeze(model, choose_layer):\n",
        "  count = 0\n",
        "  for child in model.children():\n",
        "    count+=1 \n",
        "    if count > (choose_layer + 3): \n",
        "      for param in child.parameters():\n",
        "        param.requires_grad = False\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uEaQk9-3wtVf"
      },
      "outputs": [],
      "source": [
        "#選擇哪一層之後需要解凍結\n",
        "def unfreeze(model, choose_layer):\n",
        "  count = 0\n",
        "  for child in model.children():\n",
        "    count+=1 \n",
        "    if count > (choose_layer + 3): \n",
        "      for param in child.parameters():\n",
        "        param.requires_grad = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5hHFfL8O4Th_"
      },
      "outputs": [],
      "source": [
        "class Discriminator(torch.nn.Module):\n",
        "    def __init__(self, channels):\n",
        "        super().__init__()\n",
        "        # Filters [256, 512, 1024]\n",
        "        # Input_dim = channels (Cx64x64)\n",
        "        # Output_dim = 1\n",
        "        self.main_module = nn.Sequential(\n",
        "            # Omitting batch normalization in critic because our new penalized training objective (WGAN with gradient penalty) is no longer valid\n",
        "            # in this setting, since we penalize the norm of the critic's gradient with respect to each input independently and not the enitre batch.\n",
        "            # There is not good & fast implementation of layer normalization --> using per instance normalization nn.InstanceNorm2d()\n",
        "            # Image (Cx32x32)\n",
        "\n",
        "\n",
        "            nn.Conv2d(in_channels=channels, out_channels=256, kernel_size=3, stride=2, padding=1),\n",
        "            nn.InstanceNorm2d(256, affine=True),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "\n",
        "            # State (256x16x16)\n",
        "            nn.Conv2d(in_channels=256, out_channels=512, kernel_size=3, stride=2, padding=1),\n",
        "            nn.InstanceNorm2d(512, affine=True),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "\n",
        "\n",
        "            # State (512x8x8)\n",
        "            nn.Conv2d(in_channels=512, out_channels=1024, kernel_size=3, stride=2, padding=1),\n",
        "            nn.InstanceNorm2d(1024, affine=True),\n",
        "            nn.LeakyReLU(0.2, inplace=True))\n",
        "            # output of main module --> State (1024x4x4)\n",
        "\n",
        "        self.output = nn.Sequential(\n",
        "            # The output of D is no longer a probability, we do not apply sigmoid at the output of D.\n",
        "            nn.Conv2d(in_channels=1024, out_channels=1, kernel_size=4, stride=1, padding=0))\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.main_module(x)\n",
        "\n",
        "        return self.output(x)\n",
        "        \n",
        "    def feature_extraction(self, x):\n",
        "        # Use discriminator for feature extraction then flatten to vector of 16384\n",
        "        x = self.main_module(x)\n",
        "        return x.view(-1, 1024*4*4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xUk4QqUzwzfb"
      },
      "outputs": [],
      "source": [
        "def gradient_penalty(D, xr, xf):\n",
        "    \"\"\"\n",
        "    :param D:\n",
        "    :param xr: [b, 2]\n",
        "    :param xf: [b, 2]\n",
        "    :return:\n",
        "    \"\"\"\n",
        "    '''\n",
        "    # [b, 1]\n",
        "    t = torch.rand(batch_size, 1, 1, 1).cuda()\n",
        "    # [b, 1] => [b, 2]  broadcasting so t is the same for x1 and x2\n",
        "    t = t.expand_as(xr)\n",
        "    # interpolation\n",
        "    mid = t * xr + (1 - t) * xf\n",
        "    # set it to require grad info\n",
        "    mid.requires_grad_()\n",
        "    pred = D(mid)\n",
        "    grads = autograd.grad(outputs=pred, inputs=mid,\n",
        "                          grad_outputs=torch.ones_like(pred),\n",
        "                          create_graph=True, retain_graph=True, only_inputs=True)[0]\n",
        "    gp = torch.pow(grads.norm(2, dim=1) - 1, 2).mean() * 10\n",
        "    '''\n",
        "    eta = torch.FloatTensor(batch_size,1,1,1).uniform_(0,1)\n",
        "    eta = eta.expand(batch_size, xr.size(1), xr.size(2), xr.size(3))\n",
        "    eta = eta.cuda()\n",
        "\n",
        "    interpolated = eta * xr + ((1 - eta) * xf)\n",
        "    interpolated = interpolated.cuda()\n",
        "    interpolated = interpolated\n",
        "\n",
        "    # define it to calculate gradient\n",
        "    interpolated = Variable(interpolated, requires_grad=True)\n",
        "\n",
        "    # calculate probability of interpolated examples\n",
        "    prob_interpolated = D(interpolated)\n",
        "\n",
        "    # calculate gradients of probabilities with respect to examples\n",
        "    gradients = autograd.grad(outputs=prob_interpolated, inputs=interpolated,\n",
        "                            grad_outputs=torch.ones(\n",
        "                                prob_interpolated.size()).cuda() if torch.cuda.is_available() else torch.ones(\n",
        "                                prob_interpolated.size()),\n",
        "                            create_graph=True, retain_graph=True)[0]\n",
        "\n",
        "    grad_penalty = ((gradients.norm(2, dim=1) - 1) ** 2).mean() * 10\n",
        "    return grad_penalty\n",
        "\n",
        "    #return gp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wJDlnARNw7SY"
      },
      "outputs": [],
      "source": [
        "h_dim = 400\n",
        "batch_size = 32"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IbogsjM1wzh4"
      },
      "outputs": [],
      "source": [
        "#依batch_size讀入a資料(有iterator特性)\n",
        "def data_generator_A(x_train_A):\n",
        "  global e, batch_size\n",
        "  train_loader = torch.utils.data.DataLoader(my_Dataset(x_train_A, y_train_A), batch_size = batch_size, shuffle= True,num_workers=4, pin_memory=True, drop_last=True)\n",
        "  while True:\n",
        "    for imgs,labels in train_loader:\n",
        "      yield imgs, labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_NBXPpd9wzkP"
      },
      "outputs": [],
      "source": [
        "#依batch_size讀入b資料(有iterator特性)\n",
        "def data_generator_B(x_train_B):\n",
        "  global batch_size\n",
        "  train_loader = torch.utils.data.DataLoader(my_Dataset(x_train_B, y_train_B), batch_size = batch_size, shuffle= True,num_workers=4, pin_memory=True, drop_last=True)\n",
        "  while True:\n",
        "    for imgs,labels in train_loader:\n",
        "      yield imgs, labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9SLcUFfvw7Up"
      },
      "outputs": [],
      "source": [
        "#權重初始化\n",
        "def weights_init(m):\n",
        "    classname = m.__class__.__name__\n",
        "    print('classname:', classname)\n",
        "\n",
        "    if classname.find('Conv') != -1:\n",
        "        nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
        "    elif classname.find('InstanceNorm') != -1:\n",
        "        nn.init.normal_(m.weight.data, 1.0, 0.02)\n",
        "        nn.init.constant_(m.bias.data, 0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bGhk0Klo_BGb"
      },
      "outputs": [],
      "source": [
        "#計算正確預測量\n",
        "def compute_correct(model, train_loader, loss_fn):\n",
        "  correct = 0\n",
        "  total = 0\n",
        "  with torch.no_grad():\n",
        "    for imgs, labels in train_loader:\n",
        "        imgs = imgs.to(device = device)\n",
        "        labels = labels.to(device = device)\n",
        "        outputs = model(imgs)\n",
        "        predicted = torch.max(outputs,dim = 1)\n",
        "        total += labels.shape[0]\n",
        "        correct += int((predicted.indices == labels).sum())\n",
        "  \n",
        "  return correct/total\n",
        "\n",
        "def training_loop(n_epochs,optimizer,model,loss_fn,train_dataset):\n",
        "  train_loader = torch.utils.data.DataLoader(train_dataset,batch_size = 32,shuffle= True,num_workers=4, pin_memory=True, drop_last=True)\n",
        "  \n",
        "  for epoch in range(0,n_epochs):\n",
        "    #批次\n",
        "    \n",
        "    loss_train = 0.0\n",
        "    count = 1\n",
        "    model.train()  #change\n",
        "    for imgs,labels in train_loader:\n",
        "      imgs = imgs.to(device = device)\n",
        "      labels = labels.to(device = device)\n",
        "      #print(count)\n",
        "      outputs = model(imgs)\n",
        "\n",
        "      r_loss = loss_fn(outputs,labels)\n",
        "      regularization_loss = 0\n",
        "      for param in model.parameters():\n",
        "        regularization_loss += torch.sum(param.pow(2.0))\n",
        "\n",
        "      loss = r_loss + 0.0001 * regularization_loss\n",
        "\n",
        "      optimizer.zero_grad()\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "      loss_train += r_loss.item()\n",
        "\n",
        "    model.eval()  #change\n",
        "    correct = compute_correct(model, train_loader, loss_fn)#, val_correct, val_loss\n",
        "    \n",
        "    print('Epoch {}, Training loss {}, Training accuracy {}'.format(epoch + 1, loss_train/len(train_loader), correct))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LDs6fcqIwtbj"
      },
      "outputs": [],
      "source": [
        "model_name = '/content/drive/MyDrive/charliesModel/420_35ep_satu.pt'   #選擇source model\n",
        "\n",
        "choose_layer = 1    #選擇要萃取哪一卷積層的特徵圖   \n",
        "                    #0 -> 'layer1.0.conv1, 1 -> layer2.0.conv1, 2 -> 'layer3.0.conv1\n",
        "                    #0 -> 64 1 -> 256 2 -> 512 (每一層channel 數)\n",
        "\n",
        "module_name = None\n",
        "d_input_ch = None\n",
        "\n",
        "if choose_layer == 0:\n",
        "  module_name = 'layer1.0.conv1'\n",
        "  d_input_ch = 64  #d_input_ch指Discriminator的input channel數\n",
        "elif choose_layer == 1:\n",
        "  module_name = 'layer2.0.conv1'\n",
        "  d_input_ch = 256\n",
        "elif choose_layer == 2:\n",
        "  module_name = 'layer3.0.conv1'\n",
        "  d_input_ch = 512\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U_V5toQm-uBU",
        "outputId": "990d0f1b-066d-4dc1-8b47-ccb74a4a57b0"
      },
      "outputs": [],
      "source": [
        "torch.manual_seed(23)\n",
        "np.random.seed(23)\n",
        "device = torch.device('cuda')\n",
        "all_imags = None\n",
        "\n",
        "model_A = models.resnet50(pretrained=False)  #change\n",
        "fc_feature = model_A.fc.in_features    #change\n",
        "model_A.fc = torch.nn.Linear(fc_feature,8)  #change\n",
        "model_A.load_state_dict(torch.load(model_name)) \n",
        "#model_A = torch.load(model_name)\n",
        "model_A = model_A.to(device=torch.device(\"cuda\"))\n",
        "\n",
        "dict_modules(model_A, 'A')\n",
        "\n",
        "model_B = copy.deepcopy(model_A)\n",
        "model_B = model_B.to(device=torch.device(\"cuda\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jaaPLYE9gGCL"
      },
      "outputs": [],
      "source": [
        "#用來儲存模型\n",
        "torch.save(model_B,'/content/drive/My Drive/420_20ep_light.pt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "40IimMg3f7yf"
      },
      "outputs": [],
      "source": [
        "#再開始訓練之前，先凍結，因為先更新generator，才使用分類loss更新整個B模型\n",
        "freeze(model_B, choose_layer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iFOkSbHiw7XA",
        "outputId": "1769e357-159f-458b-b846-4a2b38d5682d"
      },
      "outputs": [],
      "source": [
        "from torch.nn.common_types import T\n",
        "from torch.optim.lr_scheduler import LambdaLR\n",
        "D = Discriminator(d_input_ch).to(device)\n",
        "D.apply(weights_init)\n",
        "e = 0\n",
        "data_iter_A = data_generator_A(x_train_A)  #讀入第一批A資料\n",
        "data_iter_B = data_generator_B(x_train_B)  #讀入第一批B資料\n",
        "\n",
        "optim_G = torch.optim.Adam(model_B.parameters(), lr=1e-6, betas=(0.5, 0.9))\n",
        "optim_D = torch.optim.Adam(D.parameters(), lr=1e-6, betas=(0.5, 0.9))\n",
        "optimizer = torch.optim.Adam(model_B.parameters(),lr = 1e-6, betas=(0.5, 0.9))\n",
        "\n",
        "scheduler_D = torch.optim.lr_scheduler.ExponentialLR(optim_D, gamma=0.8) \n",
        "\n",
        "one = torch.tensor(1, dtype=torch.float)\n",
        "mone = one * -1\n",
        "one = one.cuda()\n",
        "mone = mone.cuda()\n",
        "\n",
        "loss_fn = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "for epoch in range(5):\n",
        "    e = epoch\n",
        "    dict_modules(model_B, 'B')\n",
        "    # Requires grad, Generator requires_grad = False\n",
        "    for p in D.parameters():\n",
        "        p.requires_grad = True\n",
        "    d_loss_real = 0\n",
        "    d_loss_fake = 0\n",
        "    Wasserstein_D = 0\n",
        "\n",
        "    # 1. train D first\n",
        "    for _ in range(3):  # train D 5 times, adjustable\n",
        "      for p in D.parameters():\n",
        "        p.requires_grad = True\n",
        "\n",
        "      D.zero_grad()\n",
        "\n",
        "      # 1.1 train on real data\n",
        "      a, a_labels = next(data_iter_A)\n",
        "      a = a.to(device)\n",
        "      a_labels = a_labels.to(device)\n",
        "\n",
        "      xr = feature_map(model_B, a, choose_layer, module_name, 'B').cuda() #萃取A資料特徵圖\n",
        "      # Train discriminator\n",
        "      # WGAN - Training discriminator more iterations than generator\n",
        "      # Train with real images\n",
        "      d_loss_real = D(xr)  #餵給Discriminator\n",
        "      d_loss_real = d_loss_real.mean() #計算期望值\n",
        "      d_loss_real.backward(mone)\n",
        "\n",
        "      b, b_labels = next(data_iter_B)\n",
        "      b = b.to(device)\n",
        "      b_labels = b_labels.to(device)\n",
        "      xf = feature_map(model_B, b, choose_layer, module_name, 'B').cuda() #萃取B資料特徵圖\n",
        "\n",
        "      d_loss_fake = D(xf)  #餵給Discriminator\n",
        "      d_loss_fake = d_loss_fake.mean() #計算期望值\n",
        "      d_loss_fake.backward(one)\n",
        "\n",
        "      # Train with gradient penalty\n",
        "      gp = gradient_penalty(D, xr, xf.detach())\n",
        "      gp.backward()\n",
        "      \n",
        "      d_loss = d_loss_fake - d_loss_real + gp\n",
        "      Wasserstein_D = d_loss_real - d_loss_fake\n",
        "      optim_D.step()  #更新Discriminator\n",
        "\n",
        "      del xr\n",
        "\n",
        "\n",
        "      # Generator update\n",
        "      for p in D.parameters():\n",
        "        p.requires_grad = False  # to avoid computation\n",
        "\n",
        "      correct = 0\n",
        "      total = 0\n",
        "\n",
        "      model_B.zero_grad()\n",
        "      D.zero_grad()\n",
        "      \n",
        "      # train generator\n",
        "      # compute loss with fake images\n",
        "      g_loss = D(xf)\n",
        "      g_loss = g_loss.mean()\n",
        "      g_loss = g_loss.requires_grad_()\n",
        "      g_loss.backward(mone)    #更新Generator(模型前部分)\n",
        "      \n",
        "      \n",
        "      unfreeze(model_B, choose_layer)  #解凍，以便使用分類loss更新整個模型\n",
        "\n",
        "      c = torch.cat((a,b), 0)\n",
        "      c_labels = torch.cat((a_labels, b_labels))\n",
        "      \n",
        "      pred_labels = model_B(c)\n",
        "      classifer_loss = loss_fn(pred_labels,b_labels)\n",
        "      regularization_loss = 0\n",
        "      for param in model_B.parameters():\n",
        "        regularization_loss += torch.sum(param.pow(2.0))\n",
        "\n",
        "      loss = classifer_loss #+ 0.0001 * regularization_loss\n",
        "      loss.backward()\n",
        "\n",
        "      optimizer.step()   #更新整體模型\n",
        "      optimizer.zero_grad()   \n",
        "      \n",
        "      freeze(model_B, choose_layer)  #凍結模型後部分\n",
        "\n",
        "      model_B.eval()\n",
        "      predicted = torch.max(pred_labels,dim = 1)\n",
        "      total += c_labels.shape[0]\n",
        "      correct += int((predicted.indices == c_labels).sum())\n",
        "      model_B.train()\n",
        "      del c\n",
        "      del c_labels\n",
        "      torch.cuda.empty_cache()\n",
        "\n",
        "      \n",
        "\n",
        "    if epoch % 5 == 0:\n",
        "      scheduler_D.step()\n",
        "    \n",
        "    if epoch % 1 == 0:\n",
        "        print(\"lossr:\", d_loss_real.item(), \" lossf:\", d_loss_fake.item(), \" gp:\", gp.item())#,\"sigma:\", sigma_loss.item()\n",
        "        print(\"epoch:\", epoch, \" loss_D:\", d_loss.item(),\" loss_G:\", g_loss.item(), \" loss_class:\", classifer_loss.item(), \"acc:\", correct / total,\"\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "erxqxTlAB64w",
        "outputId": "7f801181-0a30-4b5b-a096-31450032a1bc"
      },
      "outputs": [],
      "source": [
        "#計算準確率\n",
        "\n",
        "test_total = 0\n",
        "test_loss_train = 0.\n",
        "total_accuracy = 0.\n",
        "test_correct = 0\n",
        "\n",
        "test_dataset = my_Dataset(x_test_B, y_test_B)\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset , batch_size = 1,shuffle = False,num_workers=4, pin_memory=True, drop_last=True)\n",
        "\n",
        "loss_fn = torch.nn.CrossEntropyLoss()\n",
        "error_label_counetr = [0]*8\n",
        "model_B.eval()\n",
        "with torch.no_grad():\n",
        "  for imgs, labels in test_loader:  #一個for跑20張圖\n",
        "    imgs = imgs.to(device = device)\n",
        "    labels = labels.to(device = device)\n",
        "    test_outputs = model_B(imgs)  #CHANGE\n",
        "    test_loss = loss_fn(test_outputs,labels)\n",
        "\n",
        "    test_loss_train += test_loss.item()\n",
        "    test_predicted = torch.max(test_outputs,dim = 1) #https://blog.csdn.net/cunchi4221/article/details/107471005\n",
        "    test_total += labels.shape[0]\n",
        "    test_correct += int((test_predicted.indices == labels).sum())\n",
        "    \n",
        "  print(test_correct, test_total)\n",
        "  total_accuracy += test_correct/test_total\n",
        "\n",
        "  print(total_accuracy)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
